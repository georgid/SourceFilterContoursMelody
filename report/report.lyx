#LyX 2.2 created this file. For more info see http://www.lyx.org/
\lyxformat 508
\begin_document
\begin_header
\save_transient_properties true
\origin unavailable
\textclass article
\use_default_options true
\maintain_unincluded_children false
\language english
\language_package default
\inputencoding auto
\fontencoding global
\font_roman "default" "default"
\font_sans "default" "default"
\font_typewriter "default" "default"
\font_math "auto" "auto"
\font_default_family default
\use_non_tex_fonts false
\font_sc false
\font_osf false
\font_sf_scale 100 100
\font_tt_scale 100 100
\graphics default
\default_output_format default
\output_sync 0
\bibtex_command default
\index_command default
\paperfontsize default
\use_hyperref false
\papersize default
\use_geometry false
\use_package amsmath 1
\use_package amssymb 1
\use_package cancel 1
\use_package esint 1
\use_package mathdots 1
\use_package mathtools 1
\use_package mhchem 1
\use_package stackrel 1
\use_package stmaryrd 1
\use_package undertilde 1
\cite_engine basic
\cite_engine_type default
\biblio_style plain
\use_bibtopic false
\use_indices false
\paperorientation portrait
\suppress_date false
\justification true
\use_refstyle 1
\index Index
\shortcut idx
\color #008000
\end_index
\secnumdepth 3
\tocdepth 3
\paragraph_separation indent
\paragraph_indentation default
\quotes_language english
\papercolumns 1
\papersides 1
\paperpagestyle default
\tracking_changes false
\output_changes false
\html_math_output 0
\html_css_as_file 0
\html_be_strict false
\end_header

\begin_body

\begin_layout Section
Introduction
\end_layout

\begin_layout Standard
Detecting vocal segments is an important problem (copy from Lehner).
 Compared to speech, usually singing segments non-interrupted by pauses
 are longer.
 A segment corresponds to a melodic phrase.
 Segmentation into some candidate segments might be meaningful for singing
 voice detection, as the nature of voice within a segment usually have coherent
 characteristics: similar dynamics, pitch and timbre.
 Despite that, in most VD approaches disision is taken per frame, the context
 of a contour is lost.
 
\end_layout

\begin_layout Standard
On the other hand detection of pitch contours has been used for predominant
 melody extraction.
 Candidate segments pitch-continuous and salience-continuous nature are
 selected and classified as being from main melody or not.
 Using only pitch-salience features gives VD with high false alarms.
 One reason is that salient contours from background instruments are detected
 as vocal.
 In this work we propose to extend a contour-classification based approach
 by adding timbral features to the classifier.
 In particular we exploit features that capture the fluctuating timbre of
 singing voice compared to other instruments
\begin_inset Note Note
status open

\begin_layout Plain Layout
and propose a new feature
\end_layout

\end_inset

.
 
\end_layout

\begin_layout Section
Related work
\end_layout

\begin_layout Standard
vocal-non vocal timbral features, 
\begin_inset Note Note
status open

\begin_layout Plain Layout
view durrieus voicing concept: source-filter model
\end_layout

\end_inset


\end_layout

\begin_layout Subsection
static features: 
\end_layout

\begin_layout Standard
bark bands from Nadine
\end_layout

\begin_layout Standard
Fujihara - amplitudes + f0
\end_layout

\begin_layout Standard
Lehner - MFCCs
\end_layout

\begin_layout Subsection
dynamic features
\end_layout

\begin_layout Standard
A contour has continuous pitch, so relatively same pitch .
 IF no big pitch range of pitch, relatively similar spectral shape for a
 musical instrument.
 But a vocal contour might vary the the timbre because of vowels.
 
\end_layout

\begin_layout Standard
Beginning of contour is not stable, so take 10:90 percent of contour time
\end_layout

\begin_layout Section
Approach
\end_layout

\begin_layout Standard
At a given frame if there is at least one melodic contour, it is considered
 as voiced.
 
\end_layout

\begin_layout Standard
no Viterbi decoding
\end_layout

\begin_layout Standard
\begin_inset Note Comment
status open

\begin_layout Plain Layout
1.
 Extract contours from all data and save: melodyExtractionFromSalienceFunction.ma
in
\end_layout

\begin_layout Plain Layout
2.
 run_contour_training_melody_extraction.py
\end_layout

\begin_layout Plain Layout
- 3.1 for all contours overlap with ground truth eu.compute_all_overlaps
\end_layout

\begin_layout Plain Layout
- cross validate best depth of CRF cu.cross_val_sweep
\end_layout

\begin_layout Plain Layout
- classify all contours and get scikitlearn metrics: cu.clf_predictions
\end_layout

\begin_layout Plain Layout
- get threshold with best f-measure on validation dataset get_best_threshold(Y_v
alid, P_valid) on validation
\end_layout

\begin_layout Plain Layout
- classify test contours : contour_probs
\end_layout

\begin_layout Plain Layout
- melody decoding: gm.melody_from_clf
\end_layout

\end_inset


\end_layout

\begin_layout Section
Evaluation
\end_layout

\begin_layout Standard
Evaluated on datasets: iKala easy one and medleyDB?
\end_layout

\begin_layout Standard
reproduce Bernhards code on iKala
\end_layout

\end_body
\end_document
